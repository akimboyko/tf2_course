{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy and Distribute TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will learn how to deploy TensorFlow models to TensorFlow Serving (TFS), using the REST API or the gRPC API, and how to train a model across multiple devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.6.8 |Anaconda, Inc.| (default, Dec 29 2018, 19:04:46) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "matplotlib 3.0.2\n",
      "numpy 1.15.4\n",
      "pandas 0.24.1\n",
      "sklearn 0.20.1\n",
      "tensorflow 2.0.0-dev20190126\n",
      "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print(\"python\", sys.version)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sys.version_info >= (3, 5) # Python ≥3.5 required\n",
    "assert tf.__version__ >= \"2.0\"    # TensorFlow ≥2.0 required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exercise](https://c1.staticflickr.com/9/8101/8553474140_c50cf08708_b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 – Deploying a Model to TensorFlow Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Load a `SavedModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.\n",
    "X_test = X_test / 255.\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000==============================] - 2s 42us/sample - loss: 1.4335 - acc: 0.5712 - val_loss: 1.0148 - val_acc: 0.6870\n",
      "Epoch 2/10\n",
      "55000/55000==============================] - 2s 39us/sample - loss: 0.9095 - acc: 0.7065 - val_loss: 0.8134 - val_acc: 0.7360\n",
      "Epoch 3/10\n",
      "55000/55000==============================] - 2s 37us/sample - loss: 0.7796 - acc: 0.7408 - val_loss: 0.7287 - val_acc: 0.7628\n",
      "Epoch 4/10\n",
      "55000/55000==============================] - 2s 37us/sample - loss: 0.7125 - acc: 0.7649 - val_loss: 0.6750 - val_acc: 0.7790\n",
      "Epoch 5/10\n",
      "55000/55000==============================] - 2s 37us/sample - loss: 0.6682 - acc: 0.7796 - val_loss: 0.6392 - val_acc: 0.7922\n",
      "Epoch 6/10\n",
      "55000/55000==============================] - 2s 43us/sample - loss: 0.6353 - acc: 0.7914 - val_loss: 0.6106 - val_acc: 0.8006\n",
      "Epoch 7/10\n",
      "55000/55000==============================] - 3s 48us/sample - loss: 0.6102 - acc: 0.7989 - val_loss: 0.5931 - val_acc: 0.8088\n",
      "Epoch 8/10\n",
      "55000/55000==============================] - 3s 51us/sample - loss: 0.5900 - acc: 0.8066 - val_loss: 0.5724 - val_acc: 0.8152\n",
      "Epoch 9/10\n",
      "55000/55000==============================] - 3s 47us/sample - loss: 0.5734 - acc: 0.8111 - val_loss: 0.5573 - val_acc: 0.8188\n",
      "Epoch 10/10\n",
      "55000/55000==============================] - 2s 38us/sample - loss: 0.5594 - acc: 0.8157 - val_loss: 0.5453 - val_acc: 0.8212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15f4f6b70>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"my_fashion_mnist\"\n",
    "!rm -rf {MODEL_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model_version = int(time.time())\n",
    "model_path = os.path.join(MODEL_NAME, str(model_version))\n",
    "os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(MODEL_NAME):\n",
    "    indent = '    ' * root.count(os.sep)\n",
    "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "    for filename in files:\n",
    "        print('{}{}'.format(indent + '    ', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir {model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir {model_path} --tag_set serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir {model_path} --tag_set serve \\\n",
    "                      --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir {model_path} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: as you can see, the method name is empty. This is [a bug](https://github.com/tensorflow/tensorflow/issues/25235), hopefully it will be fixed shortly. In the meantime, you must use `keras.experimental.export()` instead of `tf.saved_model.save()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {MODEL_NAME}\n",
    "model_path = keras.experimental.export(model, MODEL_NAME).decode(\"utf-8\")\n",
    "!saved_model_cli show --dir {model_path} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a few test instances to a `npy` file so we can pass them easily to our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]\n",
    "np.save(\"my_fashion_mnist_tests.npy\", X_new, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flatten_1_input'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_name = model.input_names[0]\n",
    "input_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's use `saved_model_cli` to make predictions for the instances we just saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/a.boyko/anaconda3/envs/ml.crash-course/bin/saved_model_cli\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/a.boyko/anaconda3/envs/ml.crash-course/lib/python3.6/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 909, in main\n",
      "    args.func(args)\n",
      "  File \"/Users/a.boyko/anaconda3/envs/ml.crash-course/lib/python3.6/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 643, in run\n",
      "    init_tpu=args.init_tpu, tf_debug=args.tf_debug)\n",
      "  File \"/Users/a.boyko/anaconda3/envs/ml.crash-course/lib/python3.6/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 316, in run_saved_model_with_feed_dict\n",
      "    (input_key_name, '\"' + '\", \"'.join(inputs_tensor_info.keys()) + '\"'))\n",
      "ValueError: \"flatten_1_input\" is not a valid input key. Please choose from \"flatten_input\", or use --show option.\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli run --dir {model_path} --tag_set serve \\\n",
    "                     --signature_def serving_default    \\\n",
    "                     --inputs {input_name}=my_fashion_mnist_tests.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install [Docker](https://docs.docker.com/install/) if you don't have it already. Then run:\n",
    "\n",
    "```bash\n",
    "docker pull tensorflow/serving\n",
    "\n",
    "docker run -it --rm -p 8501:8501 \\\n",
    "   -v \"`pwd`/my_fashion_mnist:/models/my_fashion_mnist\" \\\n",
    "   -e MODEL_NAME=my_fashion_mnist \\\n",
    "   tensorflow/serving\n",
    "```\n",
    "\n",
    "Once you are finished using it, press Ctrl-C to shut down the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"signature_name\": \"serving_default\", \"instances\": [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0,... 0.0, 0.3843137254901961, 0.6235294117647059, 0.2784313725490196, 0.0, 0.0, 0.26666666666666666, 0.6901960784313725, 0.6431372549019608, 0.22745098039215686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_data_json = json.dumps({\n",
    "    \"signature_name\": \"serving_default\",\n",
    "    \"instances\": X_new.tolist(),\n",
    "})\n",
    "print(input_data_json[:200] + \"...\" + input_data_json[-200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use TensorFlow Serving's REST API to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "SERVER_URL = 'http://localhost:8501/v1/models/my_fashion_mnist:predict'\n",
    "            \n",
    "response = requests.post(SERVER_URL, data=input_data_json)\n",
    "response.raise_for_status()\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['predictions'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.22, 0.02, 0.62],\n",
       "       [0.  , 0.  , 0.93, 0.  , 0.02, 0.  , 0.05, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = np.array(response[\"predictions\"])\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Serialized Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized = []\n",
    "for image in X_new:\n",
    "    image_data = tf.train.FloatList(value=image.ravel())\n",
    "    features = tf.train.Features(\n",
    "        feature={\n",
    "            \"image\": tf.train.Feature(float_list=image_data),\n",
    "        }\n",
    "    )\n",
    "    example = tf.train.Example(features=features)\n",
    "    serialized.append(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\\n\\xd3\\x18\\n\\xd0\\x18\\n\\x05image\\x12\\xc6\\x18\\x12\\xc3\\x18\\n\\xc0\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00...',\n",
       " b'\\n\\xd3\\x18\\n\\xd0\\x18\\n\\x05image\\x12\\xc6\\x18\\x12\\xc3\\x18\\n\\xc0\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xd1\\xd0P=\\x87\\x86\\x86>\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc9\\xc8H>\\x99\\x98\\x18>\\x00\\x00\\x00\\x00\\x00\\x00...',\n",
       " b'\\n\\xd3\\x18\\n\\xd0\\x18\\n\\x05image\\x12\\xc6\\x18\\x12\\xc3\\x18\\n\\xc0\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x81\\x80\\x80;\\x00\\x00\\x00\\x00\\x87\\x86\\x86>\\xb2\\xb11?\\x82\\x81\\x01?\\x9a\\x99\\x19?\\xeb\\xea\\xea>\\x82\\x81\\x01?\\x93\\x92\\x12?\\x8e\\x8d\\r?\\xb0\\xaf/?\\x00\\x00...']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[data[:100]+b'...' for data in serialized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_images(serialized):\n",
    "    expected_features = {\n",
    "        \"image\": tf.io.FixedLenFeature([28 * 28], dtype=tf.float32)\n",
    "    }\n",
    "    examples = tf.io.parse_example(serialized, expected_features)\n",
    "    return tf.reshape(examples[\"image\"], (-1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=150876, shape=(3, 28, 28), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_images(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_inputs = keras.layers.Input(shape=[], dtype=tf.string)\n",
    "images = keras.layers.Lambda(lambda serialized: parse_images(serialized))(serialized_inputs)\n",
    "y_proba = model(images)\n",
    "ser_model = keras.models.Model(inputs=[serialized_inputs], outputs=[y_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['__saved_model_init_op']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['__saved_model_init_op'] tensor_info:\r\n",
      "        dtype: DT_INVALID\r\n",
      "        shape: unknown_rank\r\n",
      "        name: init_1\r\n",
      "  Method name is: \r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['input_1'] tensor_info:\r\n",
      "        dtype: DT_STRING\r\n",
      "        shape: (-1)\r\n",
      "        name: input_1:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['sequential_1'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 10)\r\n",
      "        name: sequential_1/dense_3/Softmax:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "SER_MODEL_NAME = \"my_ser_fashion_mnist\"\n",
    "!rm -rf {SER_MODEL_NAME}\n",
    "ser_model_path = keras.experimental.export(ser_model, SER_MODEL_NAME).decode(\"utf-8\")\n",
    "!saved_model_cli show --dir {ser_model_path} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run -it --rm -p 8500:8500 -p 8501:8501 \\\n",
    "   -v \"`pwd`/my_ser_fashion_mnist:/models/my_ser_fashion_mnist\" \\\n",
    "   -e MODEL_NAME=my_ser_fashion_mnist \\\n",
    "   tensorflow/serving\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"signature_name\": \"serving_default\", \"instances\": [{\"b64\": \"CtMYCtAYCgVpbWFnZRLGGBLDGArAGAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...7j4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxcTEPqCfHz+Pjo4+AAAAAAAAAACJiIg+sbAwP6WkJD/p6Gg+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"}]}\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "\n",
    "ser_input_data_json = json.dumps({\n",
    "    \"signature_name\": \"serving_default\",\n",
    "    \"instances\": [{\"b64\": base64.b64encode(data).decode(\"utf-8\")}\n",
    "                  for data in serialized],\n",
    "})\n",
    "print(ser_input_data_json[:200] + \"...\" + ser_input_data_json[-200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "SER_SERVER_URL = 'http://localhost:8501/v1/models/my_ser_fashion_mnist:predict'\n",
    "            \n",
    "response = requests.post(SER_SERVER_URL, data=ser_input_data_json)\n",
    "response.raise_for_status()\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['predictions'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06, 0.1 , 0.11, 0.13, 0.09, 0.1 , 0.11, 0.1 , 0.14, 0.05],\n",
       "       [0.03, 0.1 , 0.23, 0.1 , 0.03, 0.04, 0.12, 0.2 , 0.06, 0.09],\n",
       "       [0.06, 0.22, 0.21, 0.06, 0.1 , 0.07, 0.07, 0.12, 0.03, 0.06]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = np.array(response[\"predictions\"])\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-serving-api in /Users/a.boyko/anaconda3/envs/ml.crash-course/lib/python3.6/site-packages (1.13.0)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --no-deps tensorflow-serving-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "\n",
    "channel = grpc.insecure_channel('localhost:8500')\n",
    "predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "\n",
    "request = predict_pb2.PredictRequest()\n",
    "request.model_spec.name = SER_MODEL_NAME\n",
    "request.model_spec.signature_name = \"serving_default\"\n",
    "input_name = ser_model.input_names[0]\n",
    "request.inputs[input_name].CopyFrom(tf.compat.v1.make_tensor_proto(serialized))\n",
    "\n",
    "result = predict_service.Predict(request, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outputs {\n",
       "  key: \"sequential_1\"\n",
       "  value {\n",
       "    dtype: DT_FLOAT\n",
       "    tensor_shape {\n",
       "      dim {\n",
       "        size: 3\n",
       "      }\n",
       "      dim {\n",
       "        size: 10\n",
       "      }\n",
       "    }\n",
       "    float_val: 0.06312903016805649\n",
       "    float_val: 0.09762337058782578\n",
       "    float_val: 0.10542511194944382\n",
       "    float_val: 0.13347412645816803\n",
       "    float_val: 0.0905236005783081\n",
       "    float_val: 0.10180860012769699\n",
       "    float_val: 0.11381368339061737\n",
       "    float_val: 0.10417938977479935\n",
       "    float_val: 0.1358037292957306\n",
       "    float_val: 0.054219383746385574\n",
       "    float_val: 0.034878116101026535\n",
       "    float_val: 0.0964287593960762\n",
       "    float_val: 0.22820086777210236\n",
       "    float_val: 0.10249563306570053\n",
       "    float_val: 0.029482640326023102\n",
       "    float_val: 0.043995846062898636\n",
       "    float_val: 0.11502762883901596\n",
       "    float_val: 0.20161381363868713\n",
       "    float_val: 0.055391065776348114\n",
       "    float_val: 0.09248568117618561\n",
       "    float_val: 0.05966225266456604\n",
       "    float_val: 0.220796599984169\n",
       "    float_val: 0.2118290215730667\n",
       "    float_val: 0.05706249922513962\n",
       "    float_val: 0.10297621041536331\n",
       "    float_val: 0.0744648203253746\n",
       "    float_val: 0.07118786871433258\n",
       "    float_val: 0.11612553894519806\n",
       "    float_val: 0.03078629821538925\n",
       "    float_val: 0.05510878190398216\n",
       "  }\n",
       "}\n",
       "model_spec {\n",
       "  name: \"my_ser_fashion_mnist\"\n",
       "  version {\n",
       "    value: 1551641711\n",
       "  }\n",
       "  signature_name: \"serving_default\"\n",
       "}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sequential_1'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_name = ser_model.output_names[0]\n",
    "output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 10]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = [dim.size for dim in result.outputs[output_name].tensor_shape.dim]\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06, 0.1 , 0.11, 0.13, 0.09, 0.1 , 0.11, 0.1 , 0.14, 0.05],\n",
       "       [0.03, 0.1 , 0.23, 0.1 , 0.03, 0.04, 0.12, 0.2 , 0.06, 0.09],\n",
       "       [0.06, 0.22, 0.21, 0.06, 0.1 , 0.07, 0.07, 0.12, 0.03, 0.06]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = np.array(result.outputs[output_name].float_val).reshape(shape)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exercise](https://c1.staticflickr.com/9/8101/8553474140_c50cf08708_b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 – Distributed Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0303 20:38:10.316191 140735694128000 cross_device_ops.py:979] Not all devices in `tf.distribute.Strategy` are visible to TensorFlow.\n"
     ]
    }
   ],
   "source": [
    "distribution = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with distribution.scope():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.Dense(100, activation=\"relu\"),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",\n",
    "                  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.\n",
    "X_test = X_test / 255.\n",
    "X_valid, X_train = X_train_full[:32*32*4], X_train_full[32*32*4:]\n",
    "y_valid, y_train = y_train_full[:32*32*4], y_train_full[32*32*4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I belive this is brocken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32==============================] - 9s 279ms/step - loss: 0.1733 - acc: 0.9062 - val_loss: 0.4237 - val_acc: 0.8484\n",
      "Epoch 2/10\n",
      "32/32==============================] - 9s 275ms/step - loss: 0.2854 - acc: 0.9062 - val_loss: 0.4086 - val_acc: 0.8591\n",
      "Epoch 3/10\n",
      "32/32==============================] - 9s 271ms/step - loss: 0.4695 - acc: 0.8438 - val_loss: 0.4124 - val_acc: 0.8569\n",
      "Epoch 4/10\n",
      "32/32==============================] - 9s 290ms/step - loss: 0.5898 - acc: 0.7500 - val_loss: 0.4210 - val_acc: 0.8501\n",
      "Epoch 5/10\n",
      "32/32==============================] - 8s 260ms/step - loss: 0.3731 - acc: 0.8438 - val_loss: 0.4094 - val_acc: 0.8567\n",
      "Epoch 6/10\n",
      "32/32==============================] - 9s 277ms/step - loss: 0.4206 - acc: 0.8438 - val_loss: 0.4052 - val_acc: 0.8579\n",
      "Epoch 7/10\n",
      "32/32==============================] - 8s 264ms/step - loss: 0.4030 - acc: 0.8438 - val_loss: 0.4081 - val_acc: 0.8586\n",
      "Epoch 8/10\n",
      "32/32==============================] - 9s 274ms/step - loss: 0.4383 - acc: 0.8438 - val_loss: 0.4109 - val_acc: 0.8591\n",
      "Epoch 9/10\n",
      "32/32==============================] - 9s 271ms/step - loss: 0.2365 - acc: 0.8750 - val_loss: 0.4151 - val_acc: 0.8569\n",
      "Epoch 10/10\n",
      "32/32==============================] - 9s 268ms/step - loss: 0.4188 - acc: 0.8438 - val_loss: 0.4084 - val_acc: 0.8579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1659575c0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), batch_size=1)  # working\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid[:32*32*4], y_valid[:32*32*4]),\n",
    "          steps_per_epoch=32, batch_size=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
