{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will learn how to use TensorFlow's Data API to load and preprocess data efficiently, then you will learn about the efficient `TFRecord` binary format for storing your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n",
      "matplotlib 3.0.2\n",
      "numpy 1.15.4\n",
      "pandas 0.23.4\n",
      "sklearn 0.20.1\n",
      "tensorflow 2.0.0-dev20190227\n",
      "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print(\"python\", sys.version)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sys.version_info >= (3, 5) # Python ≥3.5 required\n",
    "assert tf.__version__ >= \"2.0\"    # TensorFlow ≥2.0 required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can browse through the code examples or jump directly to the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int64>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(np.arange(10))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.repeat(3).batch(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int64)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.interleave(\n",
    "    lambda v: tf.data.Dataset.from_tensor_slices(v),\n",
    "    cycle_length=3,\n",
    "    block_length=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 7 8 4 5 2 3 9 0 6 7 4 5 1 2 8 9 6 3 0 1 2 8 9 3 4 5 6 7 "
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item.numpy(), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((2,), ()), types: (tf.int64, tf.string)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[2, 3], [4, 5], [6, 7]])\n",
    "y = np.array([\"cat\", \"dog\", \"fox\"])\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] b'cat'\n",
      "[4 5] b'dog'\n",
      "[6 7] b'fox'\n"
     ]
    }
   ],
   "source": [
    "for item_x, item_y in dataset:\n",
    "    print(item_x.numpy(), item_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: {features: (2,), label: ()}, types: {features: tf.int64, label: tf.string}>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices({\"features\": X, \"label\": y})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] b'cat'\n",
      "[4 5] b'dog'\n",
      "[6 7] b'fox'\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item[\"features\"].numpy(), item[\"label\"].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the California dataset to multiple CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading and preparing the California housing dataset. We first load it, then split it into a training set, a validation set and a test set, and finally we scale it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For very large datasets that do not fit in memory, you will typically want to split it into many files first, then have TensorFlow read these files in parallel. To demonstrate this, let's start by splitting the scaled housing dataset and saving it to 20 CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
    "    os.makedirs(housing_dir, exist_ok=True)\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filenames = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filenames.append(part_csv)\n",
    "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.c_[X_train_scaled, y_train]\n",
    "valid_data = np.c_[X_valid_scaled, y_valid]\n",
    "test_data = np.c_[X_test_scaled, y_test]\n",
    "header_cols = [\"Scaled\" + name for name in housing.feature_names] + [\"MedianHouseValue\"]\n",
    "header = \",\".join(header_cols)\n",
    "\n",
    "train_filenames = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
    "valid_filenames = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
    "test_filenames = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's take a peek at the first few lines of one of these CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledMedInc,ScaledHouseAge,ScaledAveRooms,ScaledAveBedrms,ScaledPopulation,ScaledAveOccup,ScaledLatitude,ScaledLongitude,MedianHouseValue\n",
      "-0.1939788334343112,-1.0778131900560315,-0.9433854492905827,0.01485313784785944,0.020733351231179677,-0.5729162417603235,0.9292604730832086,-1.4221552292446311,1.442\n",
      "0.7519831792363448,-1.8688949973875395,0.4054779316683507,-0.2332768194594582,1.861464900604635,0.20516532460775205,-0.9165473773933427,1.096669692658571,1.687\n"
     ]
    }
   ],
   "source": [
    "with open(train_filenames[0]) as f:\n",
    "    for i in range(3):\n",
    "        print(f.readline(), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exercise](https://c1.staticflickr.com/9/8101/8553474140_c50cf08708_b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 – Data API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1)\n",
    "Use `tf.data.Dataset.list_files()` to create a dataset that will simply list the training filenames. Iterate through its items and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_files = tf.data.Dataset.list_files(train_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=186, shape=(), dtype=string, numpy=b'datasets/housing/my_train_01.csv'>,\n",
      " <tf.Tensor: id=187, shape=(), dtype=string, numpy=b'datasets/housing/my_train_17.csv'>,\n",
      " <tf.Tensor: id=188, shape=(), dtype=string, numpy=b'datasets/housing/my_train_16.csv'>,\n",
      " <tf.Tensor: id=189, shape=(), dtype=string, numpy=b'datasets/housing/my_train_07.csv'>,\n",
      " <tf.Tensor: id=190, shape=(), dtype=string, numpy=b'datasets/housing/my_train_04.csv'>,\n",
      " <tf.Tensor: id=191, shape=(), dtype=string, numpy=b'datasets/housing/my_train_00.csv'>,\n",
      " <tf.Tensor: id=192, shape=(), dtype=string, numpy=b'datasets/housing/my_train_14.csv'>,\n",
      " <tf.Tensor: id=193, shape=(), dtype=string, numpy=b'datasets/housing/my_train_10.csv'>,\n",
      " <tf.Tensor: id=194, shape=(), dtype=string, numpy=b'datasets/housing/my_train_11.csv'>,\n",
      " <tf.Tensor: id=195, shape=(), dtype=string, numpy=b'datasets/housing/my_train_05.csv'>,\n",
      " <tf.Tensor: id=196, shape=(), dtype=string, numpy=b'datasets/housing/my_train_18.csv'>,\n",
      " <tf.Tensor: id=197, shape=(), dtype=string, numpy=b'datasets/housing/my_train_15.csv'>,\n",
      " <tf.Tensor: id=198, shape=(), dtype=string, numpy=b'datasets/housing/my_train_06.csv'>,\n",
      " <tf.Tensor: id=199, shape=(), dtype=string, numpy=b'datasets/housing/my_train_19.csv'>,\n",
      " <tf.Tensor: id=200, shape=(), dtype=string, numpy=b'datasets/housing/my_train_12.csv'>,\n",
      " <tf.Tensor: id=201, shape=(), dtype=string, numpy=b'datasets/housing/my_train_13.csv'>,\n",
      " <tf.Tensor: id=202, shape=(), dtype=string, numpy=b'datasets/housing/my_train_09.csv'>,\n",
      " <tf.Tensor: id=203, shape=(), dtype=string, numpy=b'datasets/housing/my_train_08.csv'>,\n",
      " <tf.Tensor: id=204, shape=(), dtype=string, numpy=b'datasets/housing/my_train_03.csv'>,\n",
      " <tf.Tensor: id=205, shape=(), dtype=string, numpy=b'datasets/housing/my_train_02.csv'>]\n"
     ]
    }
   ],
   "source": [
    "pprint(list(dataset_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2)\n",
    "Use the filename dataset's `interleave()` method to create a dataset that will read from these CSV files, interleaving their lines. The first argument needs to be a function (e.g., a `lambda`) that creates a `tf.data.TextLineDataset` based on a filename, and you must also set `cycle_length=5` so that the reader interleaves data from 5 files at a time. Print the first 15 elements from this dataset to see that you do indeed get interleaved lines from multiple CSV files (you should get the first line from 5 files, then the second line from these same files, then the third lines). **Tip**: To get only the first 15 elements, you can call the dataset's `take()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "? dataset.interleave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_files = dataset_files.interleave(lambda dataset_file: tf.data.TextLineDataset(dataset_file), \n",
    "                                         cycle_length=n_repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=262, shape=(), dtype=string, numpy=b'ScaledMedInc,ScaledHouseAge,ScaledAveRooms,ScaledAveBedrms,ScaledPopulation,ScaledAveOccup,ScaledLatitude,ScaledLongitude,MedianHouseValue'>,\n",
      " <tf.Tensor: id=263, shape=(), dtype=string, numpy=b'ScaledMedInc,ScaledHouseAge,ScaledAveRooms,ScaledAveBedrms,ScaledPopulation,ScaledAveOccup,ScaledLatitude,ScaledLongitude,MedianHouseValue'>,\n",
      " <tf.Tensor: id=264, shape=(), dtype=string, numpy=b'ScaledMedInc,ScaledHouseAge,ScaledAveRooms,ScaledAveBedrms,ScaledPopulation,ScaledAveOccup,ScaledLatitude,ScaledLongitude,MedianHouseValue'>,\n",
      " <tf.Tensor: id=265, shape=(), dtype=string, numpy=b'ScaledMedInc,ScaledHouseAge,ScaledAveRooms,ScaledAveBedrms,ScaledPopulation,ScaledAveOccup,ScaledLatitude,ScaledLongitude,MedianHouseValue'>,\n",
      " <tf.Tensor: id=266, shape=(), dtype=string, numpy=b'ScaledMedInc,ScaledHouseAge,ScaledAveRooms,ScaledAveBedrms,ScaledPopulation,ScaledAveOccup,ScaledLatitude,ScaledLongitude,MedianHouseValue'>,\n",
      " <tf.Tensor: id=267, shape=(), dtype=string, numpy=b'-0.10698238234932358,1.2163240512053415,-0.36522430755132806,-0.22908029443843958,-0.882749164326441,0.10033860694954831,-0.7525796749398415,0.7168468869747529,1.625'>,\n",
      " <tf.Tensor: id=268, shape=(), dtype=string, numpy=b'-0.28605575156038454,0.662566786073286,-0.3692986080768526,-0.41074201720561043,-0.8818365557248676,0.11285159127079294,0.4795204892107495,-1.0573254290483325,2.526'>,\n",
      " <tf.Tensor: id=269, shape=(), dtype=string, numpy=b'0.15159767725728873,1.849189497070548,0.09624145072689123,-0.22151619913377374,-0.6682861429567027,-0.23549309239259542,-0.8978082113986573,0.6368841910413197,3.215'>,\n",
      " <tf.Tensor: id=270, shape=(), dtype=string, numpy=b'-0.45570144997355416,-0.5240559249239759,-0.18509612395969857,0.0025173270500037444,-0.7385570052778511,-0.2028592442325915,1.4586419124330796,-0.5075818945059632,1.069'>,\n",
      " <tf.Tensor: id=271, shape=(), dtype=string, numpy=b'0.1985265274512379,1.2954322319384923,-0.13117620706149458,-0.31340495554105857,-0.8508078632713736,-0.04867319506715338,0.8589886006031342,-1.3022111853444742,2.67'>,\n",
      " <tf.Tensor: id=272, shape=(), dtype=string, numpy=b'0.052345254135042395,-0.28673138272452353,0.047219258690479195,-0.13983857637224692,0.16218768447504958,-0.01953911964379385,1.2571958779902077,-1.617064300582372,2.441'>,\n",
      " <tf.Tensor: id=273, shape=(), dtype=string, numpy=b'-0.8687905587678326,-0.28673138272452353,-0.27797755761223253,0.07067282940565517,-1.1583569620015939,-0.46218586965369224,1.3743156654569937,-0.8174373412480258,0.55'>,\n",
      " <tf.Tensor: id=274, shape=(), dtype=string, numpy=b'0.2910224531683286,-0.28673138272452353,0.347728342329676,-0.16536721847336364,-0.45291051298539114,-0.13973664455937504,1.1166521330300656,-1.3371948648153558,2.037'>,\n",
      " <tf.Tensor: id=275, shape=(), dtype=string, numpy=b'0.24493161815641462,1.2163240512053415,0.15176826834489157,-0.060074708001733666,-0.6691987515582761,-0.25430243018733373,-0.8509602964119423,0.7318398924622724,2.213'>,\n",
      " <tf.Tensor: id=276, shape=(), dtype=string, numpy=b'0.44563625425374914,-0.7613804671234283,0.16291372535066884,-0.1649498823216082,-0.32879574317141497,0.034358474822580386,1.0698042180433505,-1.0373347550649705,2.631'>]\n"
     ]
    }
   ],
   "source": [
    "pprint(list(dataset_files.take(15)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3)\n",
    "We do not care about the header lines, so let's skip them. You can use the `skip()` method for this. Print the first five elements of your final dataset to make sure it does not print any header lines. **Tip**: make sure to call `skip()` for each `TextLineDataset`, not for the interleave dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_files = dataset_files.skip(n_repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=315, shape=(), dtype=string, numpy=b'-0.10698238234932358,1.2163240512053415,-0.36522430755132806,-0.22908029443843958,-0.882749164326441,0.10033860694954831,-0.7525796749398415,0.7168468869747529,1.625'>,\n",
      " <tf.Tensor: id=316, shape=(), dtype=string, numpy=b'-0.28605575156038454,0.662566786073286,-0.3692986080768526,-0.41074201720561043,-0.8818365557248676,0.11285159127079294,0.4795204892107495,-1.0573254290483325,2.526'>,\n",
      " <tf.Tensor: id=317, shape=(), dtype=string, numpy=b'0.15159767725728873,1.849189497070548,0.09624145072689123,-0.22151619913377374,-0.6682861429567027,-0.23549309239259542,-0.8978082113986573,0.6368841910413197,3.215'>,\n",
      " <tf.Tensor: id=318, shape=(), dtype=string, numpy=b'-0.45570144997355416,-0.5240559249239759,-0.18509612395969857,0.0025173270500037444,-0.7385570052778511,-0.2028592442325915,1.4586419124330796,-0.5075818945059632,1.069'>,\n",
      " <tf.Tensor: id=319, shape=(), dtype=string, numpy=b'0.1985265274512379,1.2954322319384923,-0.13117620706149458,-0.31340495554105857,-0.8508078632713736,-0.04867319506715338,0.8589886006031342,-1.3022111853444742,2.67'>,\n",
      " <tf.Tensor: id=320, shape=(), dtype=string, numpy=b'0.052345254135042395,-0.28673138272452353,0.047219258690479195,-0.13983857637224692,0.16218768447504958,-0.01953911964379385,1.2571958779902077,-1.617064300582372,2.441'>,\n",
      " <tf.Tensor: id=321, shape=(), dtype=string, numpy=b'-0.8687905587678326,-0.28673138272452353,-0.27797755761223253,0.07067282940565517,-1.1583569620015939,-0.46218586965369224,1.3743156654569937,-0.8174373412480258,0.55'>,\n",
      " <tf.Tensor: id=322, shape=(), dtype=string, numpy=b'0.2910224531683286,-0.28673138272452353,0.347728342329676,-0.16536721847336364,-0.45291051298539114,-0.13973664455937504,1.1166521330300656,-1.3371948648153558,2.037'>,\n",
      " <tf.Tensor: id=323, shape=(), dtype=string, numpy=b'0.24493161815641462,1.2163240512053415,0.15176826834489157,-0.060074708001733666,-0.6691987515582761,-0.25430243018733373,-0.8509602964119423,0.7318398924622724,2.213'>,\n",
      " <tf.Tensor: id=324, shape=(), dtype=string, numpy=b'0.44563625425374914,-0.7613804671234283,0.16291372535066884,-0.1649498823216082,-0.32879574317141497,0.034358474822580386,1.0698042180433505,-1.0373347550649705,2.631'>,\n",
      " <tf.Tensor: id=325, shape=(), dtype=string, numpy=b'-1.1531919611708925,-0.8404886478565791,-0.4048051092108926,0.09935892225912393,-0.39267834528154977,-0.26257650780057007,-0.7057317599531264,1.6314202217134206,0.542'>,\n",
      " <tf.Tensor: id=326, shape=(), dtype=string, numpy=b'0.7401985907389805,-1.8688949973875395,0.04162501893951269,0.03887933117333287,3.0515065170562887,0.19647907832340497,-0.5839271809876698,0.5319331526286895,3.112'>,\n",
      " <tf.Tensor: id=327, shape=(), dtype=string, numpy=b'-0.6456166406021904,-0.3658395634576743,-0.0829824644772482,-0.21405643617813777,-0.6171800612685949,-0.22121995544737735,2.306589173692612,-1.3771762127820724,0.828'>,\n",
      " <tf.Tensor: id=328, shape=(), dtype=string, numpy=b'-0.04345035636131032,0.42524224387383364,0.0684747567451936,-0.2893192675267199,-0.4894148570483253,-0.05540872891832169,0.5404227786934761,-0.05779172988039626,0.877'>,\n",
      " <tf.Tensor: id=329, shape=(), dtype=string, numpy=b'-0.785931807644142,0.42524224387383364,0.07725277090328544,0.09689789334100407,0.3273698413598267,-0.011137882761981681,-0.22788302708864097,0.06714998251559576,0.529'>]\n"
     ]
    }
   ],
   "source": [
    "pprint(list(dataset_files.take(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4)\n",
    "We need to parse these CSV lines. First, experiment with the `tf.io.decode_csv()` function using the example below (e.g., look at the types, try changing or removing some field values, etc.).\n",
    "* You need to pass it the line to parse, and set the `record_defaults` argument. This must be an array containing the default value for each field, in case it is missing. This also tells TensorFlow the number of fields to expect, and the type of each field. If you do not want a default value for a given field, you must use an empty tensor of the appropriate type (e.g., `tf.constant([])` for a `float32` field, or `tf.constant([], dtype=tf.int64` for an `int64` field)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=366, shape=(), dtype=int32, numpy=1>,\n",
       " <tf.Tensor: id=367, shape=(), dtype=float32, numpy=2.0>,\n",
       " <tf.Tensor: id=368, shape=(), dtype=float64, numpy=3.0>,\n",
       " <tf.Tensor: id=369, shape=(), dtype=string, numpy=b'4'>,\n",
       " <tf.Tensor: id=370, shape=(), dtype=float32, numpy=5.0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_defaults=[0, np.nan, tf.constant(np.nan, dtype=tf.float64), \"Hello\", tf.constant([])]\n",
    "parsed_fields = tf.io.decode_csv('1,2,3,4,5', record_defaults)\n",
    "parsed_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5)\n",
    "Now you are ready to create a function to parse a CSV line:\n",
    "* Create a `parse_csv_line()` function that takes a single line as argument.\n",
    "* Call `tf.io.decode_csv()` to parse that line.\n",
    "* Call `tf.stack()` to create a single tensor containing all the input features (i.e., all fields except the last one).\n",
    "* Reshape the labels field (i.e., the last field) to give it a shape of `[1]` instead of `[]` (i.e., it must not be a scalar). You can use `tf.reshape(label_field, [1])`, or call `tf.stack([label_field])`, or use `label_field[tf.newaxis]`.\n",
    "* Return a tuple with both tensors (input features and labels).\n",
    "* Try calling it on a single line from one of the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv_line(line, n_features=9):\n",
    "    \"\"\"\n",
    "    ScaledMedInc,ScaledHouseAge,ScaledAveRooms,ScaledAveBedrms,ScaledPopulation,ScaledAveOccup,ScaledLatitude,ScaledLongitude,MedianHouseValue\n",
    "    \"\"\"\n",
    "    \n",
    "    record_defaults = [tf.constant(np.nan) for _ in range(n_features)]\n",
    "    parsed_fields = tf.io.decode_csv(line, record_defaults)\n",
    "    \n",
    "    x = tf.stack(parsed_fields[:-1])\n",
    "    y = tf.stack(parsed_fields[-1:])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.nan is np.nan)\n",
    "print(np.nan == np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = parse_csv_line('1,2,3,4,5,6,7,8,9')\n",
    "\n",
    "tf.debugging.assert_equal(x, tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6., 7., 8.]))\n",
    "tf.debugging.assert_equal(y, tf.constant([9.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"ScaledMedInc,ScaledHouseAge,ScaledAveRooms,ScaledAveBedrms,ScaledPopulation,ScaledAveOccup,ScaledLatitude,ScaledLongitude,MedianHouseValue\".split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = parse_csv_line(b'-0.739840972632228,-0.3658395634576743,-0.784679995482575,0.07414513752253027,0.7544706668961565,0.407700592469922,-0.686992593958441,0.6019005115704453,2.0')\n",
    "\n",
    "tf.debugging.assert_equal(x, tf.constant([\n",
    "    -0.739841,\n",
    "    -0.36583957,\n",
    "    -0.78468,\n",
    "     0.07414514,\n",
    "     0.75447065,\n",
    "     0.4077006,\n",
    "    -0.6869926,\n",
    "     0.6019005\n",
    "]))\n",
    "\n",
    "tf.debugging.assert_equal(y, tf.constant([2.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6)\n",
    "Now create a `csv_reader_dataset()` function that takes a list of CSV filenames and returns a dataset that will provide batches of parsed and shuffled data from these files, including the features and labels, repeating the whole data once per epoch.\n",
    "\n",
    "**Tips**:\n",
    "* Copy your code from above to get a dataset that returns interleaved lines from the given CSV files. Your function will need an argument for the `filenames`, and another for the number of files read in parallel at any given time (e.g., `n_reader`).\n",
    "* The training algorithm will need to go through the dataset many times, so you should call `repeat()` on the filenames dataset. You do not need to specify a number of repetitions, as we will tell Keras the number of iterations to run later on.\n",
    "* Gradient descent works best when the data is IID (independent and identically distributed), so you should call the `shuffle()` method. It will require the shuffling buffer size, which you can add as an argument to your function (e.g., `shuffle_buffer_size`).\n",
    "* Use the `map()` method to apply the `parse_csv_line()` function to each CSV line. You can set the `num_parallel_calls` argument to the number of threads that will parse lines in parallel. This should probably be an argument of your function (e.g., `n_parse_threads`).\n",
    "* Use the `batch()` method to bundle records into batches. You will need to specify the batch size. This should probably be an argument of your function (e.g., `batch_size`).\n",
    "* Call `prefetch(1)` on your final dataset to ensure that the next batch is loaded and parsed while the rest of your computations take place in parallel (to avoid blocking for I/O).\n",
    "* Return the resulting dataset.\n",
    "* Give every argument a reasonable default value (except for the filenames).\n",
    "* Test your function by calling it with a small batch size and printing the first couple of batches.\n",
    "* For higher performance, you can replace `dataset.map(...).batch(...)` with `dataset.apply(map_and_batch(...))`, where `map_and_batch()` is an experimental function located in `tf.data.experimental`. It will be deprecated in future versions of TensorFlow when such pipeline optimizations become automatic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filenames, n_parse_threads=5, batch_size=32,\n",
    "                       shuffle_buffer_size=10000, n_readers=5):\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.repeat()  # let make infinite dataset\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filename: tf.data.TextLineDataset(filename).skip(1),\n",
    "        cycle_length=n_readers)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(parse_csv_line, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)  # for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[-0.57281405 -0.5240559  -0.24298318  0.15274556 -0.4510853   0.11923176\n",
      "  -0.82753634  0.61189586]\n",
      " [-0.18879361  1.5327568  -0.01413399 -0.24966547 -0.65733486 -0.42945862\n",
      "   1.3696309  -0.9323837 ]\n",
      " [ 0.9390177   0.2670259   0.46980163 -0.2508443  -0.3132814   0.31472617\n",
      "  -1.3334938   1.3365577 ]]\n",
      "y = [[2.75 ]\n",
      " [1.479]\n",
      " [2.088]]\n",
      "\n",
      "\n",
      "X = [[-0.7757185  -0.04940684 -0.7331179  -0.16466767 -0.8453322   1.1710402\n",
      "  -0.77600366  0.67186785]\n",
      " [ 1.1180911   0.2670259   0.37279218 -0.21405643 -0.75133353 -0.03526263\n",
      "   1.0791738  -1.2522345 ]\n",
      " [-0.10289706 -1.1569214  -0.22683562 -0.40810654 -0.9128652  -0.09459835\n",
      "   1.411794   -0.8874047 ]]\n",
      "y = [[0.964]\n",
      " [2.479]\n",
      " [1.161]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set = csv_reader_dataset(train_filenames, batch_size=3)\n",
    "for X_batch, y_batch in train_set.take(2):\n",
    "    print(f\"X = {X_batch}\\ny = {y_batch}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7)\n",
    "Build a training set, a validation set and a test set using your `csv_reader_dataset()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = csv_reader_dataset(train_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = csv_reader_dataset(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = csv_reader_dataset(valid_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.output_shapes[0][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8)\n",
    "Build and compile a Keras model for this regression task, and use your datasets to train it, evaluate it and make predictions for the test set.\n",
    "\n",
    "**Tips**\n",
    "* Instead of passing `X_train_scaled, y_train` to the `fit()` method, pass the training dataset and specify the `steps_per_epoch` argument. This should be set to the number of instances in the training set divided by the batch size.\n",
    "* Similarly, pass the validation dataset instead of `(X_valid_scaled, y_valid)` and `y_valid`, and set the `validation_steps`.\n",
    "* For the `evaluate()` and `predict()` methods, you need to pass the test dataset, and specify the `steps` argument.\n",
    "* The `predict()` method ignores the labels in the test dataset, but if you want to be extra sure that it does not cheat, you can create a new dataset by stripping away the labels from the test set (e.g., `test_set.map(lambda X, y: X)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    return keras.models.Sequential([\n",
    "        keras.layers.Dense(30, activation=\"relu\", input_shape=train_dataset.output_shapes[0][1:]),\n",
    "        keras.layers.Dense(1),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 8])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 3.3688 - accuracy: 0.0015 - val_loss: 2.2570 - val_accuracy: 0.0020\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.9877 - accuracy: 0.0039 - val_loss: 1.4730 - val_accuracy: 0.0039\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.4436 - accuracy: 0.0020 - val_loss: 1.1308 - val_accuracy: 0.0039\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.1178 - accuracy: 0.0024 - val_loss: 0.9690 - val_accuracy: 0.0039\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.4110 - accuracy: 0.0029 - val_loss: 0.8915 - val_accuracy: 0.0039\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.0022 - accuracy: 0.0024 - val_loss: 0.8148 - val_accuracy: 0.0039\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.9070 - accuracy: 0.0039 - val_loss: 0.7732 - val_accuracy: 0.0039\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.8896 - accuracy: 0.0029 - val_loss: 0.7586 - val_accuracy: 0.0039\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.8735 - accuracy: 0.0034 - val_loss: 0.7350 - val_accuracy: 0.0039\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.8163 - accuracy: 0.0029 - val_loss: 0.7216 - val_accuracy: 0.0039\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.0029 - val_loss: 0.7126 - val_accuracy: 0.0039\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.7585 - accuracy: 0.0044 - val_loss: 0.7025 - val_accuracy: 0.0039\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.7339 - accuracy: 0.0015 - val_loss: 0.6918 - val_accuracy: 0.0039\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.7342 - accuracy: 0.0029 - val_loss: 0.6836 - val_accuracy: 0.0039\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.0024 - val_loss: 0.6738 - val_accuracy: 0.0039\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.7038 - accuracy: 0.0049 - val_loss: 0.6657 - val_accuracy: 0.0039\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.7331 - accuracy: 0.0020 - val_loss: 0.6599 - val_accuracy: 0.0039\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.7077 - accuracy: 0.0039 - val_loss: 0.6532 - val_accuracy: 0.0039\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.0029 - val_loss: 0.6606 - val_accuracy: 0.0039\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 9.7656e-04 - val_loss: 0.6421 - val_accuracy: 0.0039\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 9.7656e-04 - val_loss: 0.6356 - val_accuracy: 0.0039\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.0034 - val_loss: 0.6278 - val_accuracy: 0.0039\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.0034 - val_loss: 0.6225 - val_accuracy: 0.0039\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.0020 - val_loss: 0.6138 - val_accuracy: 0.0039\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.0024 - val_loss: 0.6075 - val_accuracy: 0.0039\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.0034 - val_loss: 0.6005 - val_accuracy: 0.0039\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.7109 - accuracy: 0.0044 - val_loss: 0.6046 - val_accuracy: 0.0039\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.0015 - val_loss: 0.5946 - val_accuracy: 0.0039\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 9.7656e-04 - val_loss: 0.5900 - val_accuracy: 0.0039\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.0039 - val_loss: 0.5843 - val_accuracy: 0.0039\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.0039 - val_loss: 0.5765 - val_accuracy: 0.0039\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.0044 - val_loss: 0.5724 - val_accuracy: 0.0039\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.0034 - val_loss: 0.5681 - val_accuracy: 0.0039\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.0024 - val_loss: 0.5641 - val_accuracy: 0.0039\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.0044 - val_loss: 0.5591 - val_accuracy: 0.0039\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.0015 - val_loss: 0.5568 - val_accuracy: 0.0039\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.0020 - val_loss: 0.5504 - val_accuracy: 0.0039\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.0024 - val_loss: 0.5455 - val_accuracy: 0.0039\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.0029 - val_loss: 0.5420 - val_accuracy: 0.0039\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.0044 - val_loss: 0.5362 - val_accuracy: 0.0039\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.0015 - val_loss: 0.5324 - val_accuracy: 0.0039\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.0029 - val_loss: 0.5275 - val_accuracy: 0.0039\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 9.7656e-04 - val_loss: 0.5246 - val_accuracy: 0.0039\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.0039 - val_loss: 0.5201 - val_accuracy: 0.0039\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.0029 - val_loss: 0.5174 - val_accuracy: 0.0039\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.0044 - val_loss: 0.5144 - val_accuracy: 0.0039\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.0020 - val_loss: 0.5132 - val_accuracy: 0.0039\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.0024 - val_loss: 0.5086 - val_accuracy: 0.0039\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.0029 - val_loss: 0.5052 - val_accuracy: 0.0039\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.0020 - val_loss: 0.5074 - val_accuracy: 0.0039\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.0034 - val_loss: 0.5010 - val_accuracy: 0.0039\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.0039 - val_loss: 0.4996 - val_accuracy: 0.0039\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.0020 - val_loss: 0.4957 - val_accuracy: 0.0039\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.0029 - val_loss: 0.4937 - val_accuracy: 0.0039\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.0044 - val_loss: 0.4928 - val_accuracy: 0.0039\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.0034 - val_loss: 0.4919 - val_accuracy: 0.0039\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.0029 - val_loss: 0.4881 - val_accuracy: 0.0039\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.0024 - val_loss: 0.4842 - val_accuracy: 0.0039\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.0024 - val_loss: 0.4821 - val_accuracy: 0.0039\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.0039 - val_loss: 0.4800 - val_accuracy: 0.0039\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.0039 - val_loss: 0.4784 - val_accuracy: 0.0039\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.0029 - val_loss: 0.4771 - val_accuracy: 0.0039\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.0029 - val_loss: 0.4736 - val_accuracy: 0.0039\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.0029 - val_loss: 0.4713 - val_accuracy: 0.0039\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.0029 - val_loss: 0.4695 - val_accuracy: 0.0039\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 9.7656e-04 - val_loss: 0.4680 - val_accuracy: 0.0039\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.0044 - val_loss: 0.4651 - val_accuracy: 0.0039\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.0044 - val_loss: 0.4656 - val_accuracy: 0.0039\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.0015 - val_loss: 0.4628 - val_accuracy: 0.0039\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.0015 - val_loss: 0.4611 - val_accuracy: 0.0039\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.0054 - val_loss: 0.4589 - val_accuracy: 0.0039\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.0015 - val_loss: 0.4577 - val_accuracy: 0.0039\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.0054 - val_loss: 0.4579 - val_accuracy: 0.0039\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.0029 - val_loss: 0.4548 - val_accuracy: 0.0039\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.0024 - val_loss: 0.4546 - val_accuracy: 0.0039\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 9.7656e-04 - val_loss: 0.4517 - val_accuracy: 0.0039\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.0020 - val_loss: 0.4502 - val_accuracy: 0.0039\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.0015 - val_loss: 0.4474 - val_accuracy: 0.0039\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.0029 - val_loss: 0.4460 - val_accuracy: 0.0039\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.0024 - val_loss: 0.4455 - val_accuracy: 0.0039\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.0029 - val_loss: 0.4435 - val_accuracy: 0.0039\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.0034 - val_loss: 0.4421 - val_accuracy: 0.0039\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.0029 - val_loss: 0.4408 - val_accuracy: 0.0039\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.0029 - val_loss: 0.4398 - val_accuracy: 0.0039\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.0020 - val_loss: 0.4405 - val_accuracy: 0.0039\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.0044 - val_loss: 0.4407 - val_accuracy: 0.0039\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.0029 - val_loss: 0.4389 - val_accuracy: 0.0039\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.0015 - val_loss: 0.4362 - val_accuracy: 0.0039\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.0020 - val_loss: 0.4354 - val_accuracy: 0.0039\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.0024 - val_loss: 0.4350 - val_accuracy: 0.0039\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.0020 - val_loss: 0.4325 - val_accuracy: 0.0039\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.0020 - val_loss: 0.4321 - val_accuracy: 0.0039\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.0044 - val_loss: 0.4308 - val_accuracy: 0.0039\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.0024 - val_loss: 0.4319 - val_accuracy: 0.0039\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.0034 - val_loss: 0.4317 - val_accuracy: 0.0039\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.0015 - val_loss: 0.4298 - val_accuracy: 0.0039\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.0034 - val_loss: 0.4281 - val_accuracy: 0.0039\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.0020 - val_loss: 0.4270 - val_accuracy: 0.0039\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.0034 - val_loss: 0.4268 - val_accuracy: 0.0039\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.0049 - val_loss: 0.4257 - val_accuracy: 0.0039\n",
      "CPU times: user 49.6 s, sys: 6.22 s, total: 55.8 s\n",
      "Wall time: 18 s\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.4288 - accuracy: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4287934530293569, 0.002105713]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='sgd', metrics=['accuracy'])\n",
    "%time history = model.fit(train_dataset, epochs=100, steps_per_epoch=64, validation_steps=32, validation_data=valid_dataset, callbacks=[keras.callbacks.EarlyStopping(patience=5)])\n",
    "\n",
    "model.evaluate(test_dataset, steps=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36287138],\n",
       "       [1.636884  ],\n",
       "       [3.065917  ],\n",
       "       ...,\n",
       "       [1.3724762 ],\n",
       "       [2.4283142 ],\n",
       "       [3.7680511 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exercise solution](https://camo.githubusercontent.com/250388fde3fac9135ead9471733ee28e049f7a37/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f302f30362f46696c6f735f736567756e646f5f6c6f676f5f253238666c69707065642532392e6a7067)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 – Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1)\n",
    "Use `tf.data.Dataset.list_files()` to create a dataset that will simply list the training filenames. Iterate through its items and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dataset = tf.data.Dataset.list_files(train_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filename_dataset:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2)\n",
    "Use the filename dataset's `interleave()` method to create a dataset that will read from these CSV files, interleaving their lines. The first argument needs to be a function (e.g., a `lambda`) that creates a `tf.data.TextLineDataset` based on a filename, and you must also set `cycle_length=5` so that the reader interleaves data from 5 files at a time. Print the first 15 elements from this dataset to see that you do indeed get interleaved lines from multiple CSV files (you should get the first line from 5 files, then the second line from these same files, then the third lines). **Tip**: To get only the first 15 elements, you can call the dataset's `take()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_readers = 5\n",
    "dataset = filename_dataset.interleave(\n",
    "    lambda filename: tf.data.TextLineDataset(filename),\n",
    "    cycle_length=n_readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in dataset.take(15):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3)\n",
    "We do not care about the header lines, so let's skip them. You can use the `skip()` method for this. Print the first five elements of your final dataset to make sure it does not print any header lines. **Tip**: make sure to call `skip()` for each `TextLineDataset`, not for the interleave dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = filename_dataset.interleave(\n",
    "    lambda filename: tf.data.TextLineDataset(filename).skip(1),\n",
    "    cycle_length=n_readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in dataset.take(5):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4)\n",
    "We need to parse these CSV lines. First, experiment with the `tf.io.decode_csv()` function using the example below (e.g., look at the types, try removing some field values, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that field 4 is interpreted as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_defaults=[0, np.nan, tf.constant(np.nan, dtype=tf.float64), \"Hello\", tf.constant([])]\n",
    "parsed_fields = tf.io.decode_csv('1,2,3,4,5', record_defaults)\n",
    "parsed_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all missing fields are replaced with their default value, when provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_fields = tf.io.decode_csv(',,,,5', record_defaults)\n",
    "parsed_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 5th field is compulsory (since we provided `tf.constant([])` as the \"default value\"), so we get an exception if we do not provide it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    parsed_fields = tf.io.decode_csv(',,,,', record_defaults)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of fields should match exactly the number of fields in the `record_defaults`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    parsed_fields = tf.io.decode_csv('1,2,3,4,5,6,7', record_defaults)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5)\n",
    "Now you are ready to create a function to parse a CSV line:\n",
    "* Create a `parse_csv_line()` function that takes a single line as argument.\n",
    "* Call `tf.io.decode_csv()` to parse that line.\n",
    "* Call `tf.stack()` to create a single tensor containing all the input features (i.e., all fields except the last one).\n",
    "* Reshape the labels field (i.e., the last field) to give it a shape of `[1]` instead of `[]` (i.e., it must not be a scalar). You can use `tf.reshape(label_field, [1])`, or call `tf.stack([label_field])`, or use `label_field[tf.newaxis]`.\n",
    "* Return a tuple with both tensors (input features and labels).\n",
    "* Try calling it on a single line from one of the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[1]\n",
    "\n",
    "def parse_csv_line(line, n_inputs=n_inputs):\n",
    "    defs = [tf.constant(np.nan)] * (n_inputs + 1)\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_csv_line(b'-0.739840972632228,-0.3658395634576743,-0.784679995482575,0.07414513752253027,0.7544706668961565,0.407700592469922,-0.686992593958441,0.6019005115704453,2.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6)\n",
    "Now create a `csv_reader_dataset()` function that takes a list of CSV filenames and returns a dataset that will provide batches of parsed and shuffled data from these files, including the features and labels, repeating the whole data once per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filenames, n_parse_threads=5, batch_size=32,\n",
    "                       shuffle_buffer_size=10000, n_readers=5):\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filename: tf.data.TextLineDataset(filename).skip(1),\n",
    "        cycle_length=n_readers)\n",
    "    dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(parse_csv_line, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version uses `map_and_batch()` to get a performance boost (but remember that this feature is experimental and will eventually be deprecated, as explained earlier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filenames, batch_size=32,\n",
    "                       shuffle_buffer_size=10000, n_readers=5):\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filename: tf.data.TextLineDataset(filename).skip(1),\n",
    "        cycle_length=n_readers)\n",
    "    dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.apply(\n",
    "        tf.data.experimental.map_and_batch(\n",
    "            parse_csv_line,\n",
    "            batch_size,\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE))\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = csv_reader_dataset(train_filenames, batch_size=3)\n",
    "for X_batch, y_batch in train_set.take(2):\n",
    "    print(\"X =\", X_batch)\n",
    "    print(\"y =\", y_batch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7)\n",
    "Build a training set, a validation set and a test set using your `csv_reader_dataset()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_set = csv_reader_dataset(train_filenames, batch_size)\n",
    "valid_set = csv_reader_dataset(valid_filenames, batch_size)\n",
    "test_set = csv_reader_dataset(test_filenames, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8)\n",
    "Build and compile a Keras model for this regression task, and use your datasets to train it, evaluate it and make predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[n_inputs]),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_set, steps_per_epoch=len(X_train) // batch_size, epochs=10,\n",
    "          validation_data=valid_set, validation_steps=len(X_valid) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_set, steps=len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_set = test_set.map(lambda X, y: X)\n",
    "model.predict(new_set, steps=len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exercise](https://c1.staticflickr.com/9/8101/8553474140_c50cf08708_b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 – The `TFRecord` binary format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can walk through these code examples or jump down to the [actual exercise](#Actual-exercise) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value: \"Arluk\"\n",
       "value: \"Fahrenheit 451\"\n",
       "value: \"L\\'\\303\\251tranger\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorite_books = [name.encode(\"utf-8\")\n",
    "                  for name in [\"Arluk\", \"Fahrenheit 451\", \"L'étranger\"]]\n",
    "favorite_books = tf.train.BytesList(value=favorite_books)\n",
    "favorite_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value: 15.5\n",
       "value: 9.5\n",
       "value: nan\n",
       "value: 6.0\n",
       "value: 9.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hours_per_month = tf.train.FloatList(value=[15.5, 9.5, np.nan, 6.0, 9.0])\n",
    "hours_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value: 42"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = tf.train.Int64List(value=[42])\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value: 1.283400058746338\n",
       "value: 103.86070251464844"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates = tf.train.FloatList(value=[1.2834, 103.8607])\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature {\n",
       "  key: \"age\"\n",
       "  value {\n",
       "    int64_list {\n",
       "      value: 42\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  key: \"coordinates\"\n",
       "  value {\n",
       "    float_list {\n",
       "      value: 1.283400058746338\n",
       "      value: 103.86070251464844\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  key: \"favorite_books\"\n",
       "  value {\n",
       "    bytes_list {\n",
       "      value: \"Arluk\"\n",
       "      value: \"Fahrenheit 451\"\n",
       "      value: \"L\\'\\303\\251tranger\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  key: \"hours_per_month\"\n",
       "  value {\n",
       "    float_list {\n",
       "      value: 15.5\n",
       "      value: 9.5\n",
       "      value: nan\n",
       "      value: 6.0\n",
       "      value: 9.0\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tf.train.Features(\n",
    "    feature={\n",
    "        \"favorite_books\": tf.train.Feature(bytes_list=favorite_books),\n",
    "        \"hours_per_month\": tf.train.Feature(float_list=hours_per_month),\n",
    "        \"age\": tf.train.Feature(int64_list=age),\n",
    "        \"coordinates\": tf.train.Feature(float_list=coordinates),\n",
    "    }\n",
    ")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"age\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 42\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"coordinates\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: 1.283400058746338\n",
       "        value: 103.86070251464844\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"favorite_books\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"Arluk\"\n",
       "        value: \"Fahrenheit 451\"\n",
       "        value: \"L\\'\\303\\251tranger\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"hours_per_month\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: 15.5\n",
       "        value: 9.5\n",
       "        value: nan\n",
       "        value: 6.0\n",
       "        value: 9.0\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = tf.train.Example(features=features)\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"\\n\\x92\\x01\\n+\\n\\x0fhours_per_month\\x12\\x18\\x12\\x16\\n\\x14\\x00\\x00xA\\x00\\x00\\x18A\\x00\\x00\\xc0\\x7f\\x00\\x00\\xc0@\\x00\\x00\\x10A\\n\\x0c\\n\\x03age\\x12\\x05\\x1a\\x03\\n\\x01*\\n8\\n\\x0efavorite_books\\x12&\\n$\\n\\x05Arluk\\n\\x0eFahrenheit 451\\n\\x0bL'\\xc3\\xa9tranger\\n\\x1b\\n\\x0bcoordinates\\x12\\x0c\\x12\\n\\n\\x08tF\\xa4?\\xae\\xb8\\xcfB\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialized_example = example.SerializeToString()\n",
    "serialized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"my_reading_data.tfrecords\"\n",
    "with tf.io.TFRecordWriter(filename) as writer:\n",
    "    for i in range(3): # you should save different examples instead! :)\n",
    "        writer.write(serialized_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"\\n\\x92\\x01\\n+\\n\\x0fhours_per_month\\x12\\x18\\x12\\x16\\n\\x14\\x00\\x00xA\\x00\\x00\\x18A\\x00\\x00\\xc0\\x7f\\x00\\x00\\xc0@\\x00\\x00\\x10A\\n\\x0c\\n\\x03age\\x12\\x05\\x1a\\x03\\n\\x01*\\n8\\n\\x0efavorite_books\\x12&\\n$\\n\\x05Arluk\\n\\x0eFahrenheit 451\\n\\x0bL'\\xc3\\xa9tranger\\n\\x1b\\n\\x0bcoordinates\\x12\\x0c\\x12\\n\\n\\x08tF\\xa4?\\xae\\xb8\\xcfB\", shape=(), dtype=string)\n",
      "tf.Tensor(b\"\\n\\x92\\x01\\n+\\n\\x0fhours_per_month\\x12\\x18\\x12\\x16\\n\\x14\\x00\\x00xA\\x00\\x00\\x18A\\x00\\x00\\xc0\\x7f\\x00\\x00\\xc0@\\x00\\x00\\x10A\\n\\x0c\\n\\x03age\\x12\\x05\\x1a\\x03\\n\\x01*\\n8\\n\\x0efavorite_books\\x12&\\n$\\n\\x05Arluk\\n\\x0eFahrenheit 451\\n\\x0bL'\\xc3\\xa9tranger\\n\\x1b\\n\\x0bcoordinates\\x12\\x0c\\x12\\n\\n\\x08tF\\xa4?\\xae\\xb8\\xcfB\", shape=(), dtype=string)\n",
      "tf.Tensor(b\"\\n\\x92\\x01\\n+\\n\\x0fhours_per_month\\x12\\x18\\x12\\x16\\n\\x14\\x00\\x00xA\\x00\\x00\\x18A\\x00\\x00\\xc0\\x7f\\x00\\x00\\xc0@\\x00\\x00\\x10A\\n\\x0c\\n\\x03age\\x12\\x05\\x1a\\x03\\n\\x01*\\n8\\n\\x0efavorite_books\\x12&\\n$\\n\\x05Arluk\\n\\x0eFahrenheit 451\\n\\x0bL'\\xc3\\xa9tranger\\n\\x1b\\n\\x0bcoordinates\\x12\\x0c\\x12\\n\\n\\x08tF\\xa4?\\xae\\xb8\\xcfB\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for serialized_example_tensor in tf.data.TFRecordDataset([filename]):\n",
    "    print(serialized_example_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"my_reading_data.tfrecords\"\n",
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "with tf.io.TFRecordWriter(filename, options) as writer:\n",
    "    for i in range(3): # you should save different examples instead! :)\n",
    "        writer.write(serialized_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"\\n\\x92\\x01\\n+\\n\\x0fhours_per_month\\x12\\x18\\x12\\x16\\n\\x14\\x00\\x00xA\\x00\\x00\\x18A\\x00\\x00\\xc0\\x7f\\x00\\x00\\xc0@\\x00\\x00\\x10A\\n\\x0c\\n\\x03age\\x12\\x05\\x1a\\x03\\n\\x01*\\n8\\n\\x0efavorite_books\\x12&\\n$\\n\\x05Arluk\\n\\x0eFahrenheit 451\\n\\x0bL'\\xc3\\xa9tranger\\n\\x1b\\n\\x0bcoordinates\\x12\\x0c\\x12\\n\\n\\x08tF\\xa4?\\xae\\xb8\\xcfB\", shape=(), dtype=string)\n",
      "tf.Tensor(b\"\\n\\x92\\x01\\n+\\n\\x0fhours_per_month\\x12\\x18\\x12\\x16\\n\\x14\\x00\\x00xA\\x00\\x00\\x18A\\x00\\x00\\xc0\\x7f\\x00\\x00\\xc0@\\x00\\x00\\x10A\\n\\x0c\\n\\x03age\\x12\\x05\\x1a\\x03\\n\\x01*\\n8\\n\\x0efavorite_books\\x12&\\n$\\n\\x05Arluk\\n\\x0eFahrenheit 451\\n\\x0bL'\\xc3\\xa9tranger\\n\\x1b\\n\\x0bcoordinates\\x12\\x0c\\x12\\n\\n\\x08tF\\xa4?\\xae\\xb8\\xcfB\", shape=(), dtype=string)\n",
      "tf.Tensor(b\"\\n\\x92\\x01\\n+\\n\\x0fhours_per_month\\x12\\x18\\x12\\x16\\n\\x14\\x00\\x00xA\\x00\\x00\\x18A\\x00\\x00\\xc0\\x7f\\x00\\x00\\xc0@\\x00\\x00\\x10A\\n\\x0c\\n\\x03age\\x12\\x05\\x1a\\x03\\n\\x01*\\n8\\n\\x0efavorite_books\\x12&\\n$\\n\\x05Arluk\\n\\x0eFahrenheit 451\\n\\x0bL'\\xc3\\xa9tranger\\n\\x1b\\n\\x0bcoordinates\\x12\\x0c\\x12\\n\\n\\x08tF\\xa4?\\xae\\xb8\\xcfB\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset([filename], compression_type=\"GZIP\")\n",
    "for serialized_example_tensor in dataset:\n",
    "    print(serialized_example_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arluk\tFahrenheit 451\tL'étranger\t\n",
      "Arluk\tFahrenheit 451\tL'étranger\t\n",
      "Arluk\tFahrenheit 451\tL'étranger\t\n"
     ]
    }
   ],
   "source": [
    "expected_features = {\n",
    "    \"favorite_books\": tf.io.VarLenFeature(dtype=tf.string),\n",
    "    \"hours_per_month\": tf.io.VarLenFeature(dtype=tf.float32),\n",
    "    \"age\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "    \"coordinates\": tf.io.FixedLenFeature([2], dtype=tf.float32),\n",
    "}\n",
    "\n",
    "for serialized_example_tensor in tf.data.TFRecordDataset(\n",
    "        [filename], compression_type=\"GZIP\"):\n",
    "    example = tf.io.parse_single_example(serialized_example_tensor,\n",
    "                                         expected_features)\n",
    "    books = tf.sparse.to_dense(example[\"favorite_books\"],\n",
    "                               default_value=b\"\")\n",
    "    for book in books:\n",
    "        print(book.numpy().decode('UTF-8'), end=\"\\t\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1)\n",
    "Write a `csv_to_tfrecords()` function that will read from a given CSV dataset (e.g., such as `train_set`, passed as an argument), and write the instances to multiple TFRecord files. The number of files should be defined by an `n_shards` argument. If there are, say, 20 shards, then the files should be named `my_train_00000-to-00019.tfrecords` to `my_train_00019-to-00019.tfrecords`, where the `my_train` prefix should be defined by an argument.\n",
    "\n",
    "**Tips**:\n",
    "* since the CSV dataset repeats the dataset forever, the function should take an argument defining the number of steps per shard, and you should use `take()` to pull only the appropriate number of batches from the CSV dataset for each shard.\n",
    "* to format 19 as `\"00019\"`, you can use `\"{:05d}\".format(19)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(x, y):\n",
    "    input_features = tf.train.FloatList(value=x)\n",
    "    label = tf.train.FloatList(value=y)\n",
    "    features = tf.train.Features(\n",
    "        feature = {\n",
    "            \"input_features\": tf.train.Feature(float_list=input_features),\n",
    "            \"label\": tf.train.Feature(float_list=label),\n",
    "        }\n",
    "    )\n",
    "    example = tf.train.Example(features=features)\n",
    "    return example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_tfrecords(filename, csv_reader_dataset, n_shards, steps_per_shard,\n",
    "                     compression_type=None):\n",
    "    options = tf.io.TFRecordOptions(compression_type=compression_type)\n",
    "    for shard in range(n_shards):\n",
    "        path = \"{}_{:05d}-of-{:05d}.tfrecords\".format(filename, shard, n_shards)\n",
    "        with tf.io.TFRecordWriter(path, options) as writer:\n",
    "            for X_batch, y_batch in csv_reader_dataset.take(steps_per_shard):\n",
    "                for x_instance, y_instance in zip(X_batch, y_batch):\n",
    "                    writer.write(serialize_example(x_instance, y_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2)\n",
    "Use this function to write the training set, validation set and test set to multiple TFRecord files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_shards = 20\n",
    "steps_per_shard = len(X_train) // batch_size // n_shards\n",
    "csv_to_tfrecords(\"my_train.tfrecords\", train_set, n_shards, steps_per_shard)\n",
    "\n",
    "n_shards = 1\n",
    "steps_per_shard = len(X_valid) // batch_size // n_shards\n",
    "csv_to_tfrecords(\"my_valid.tfrecords\", valid_set, n_shards, steps_per_shard)\n",
    "\n",
    "n_shards = 1\n",
    "steps_per_shard = len(X_test) // batch_size // n_shards\n",
    "csv_to_tfrecords(\"my_test.tfrecords\", test_set, n_shards, steps_per_shard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3)\n",
    "Write a `tfrecords_reader_dataset()` function, very similar to `csv_reader_dataset()`, that will read from multiple TFRecord files. For convenience, it should take a file prefix (such as `\"my_train\"`) and use `os.listdir()` to look for all the TFRecord files with that prefix.\n",
    "\n",
    "**Tips**:\n",
    "* You can mostly reuse `csv_reader_dataset()`, except it will use a different parsing function (based on `tf.io.parse_single_example()` instead of `tf.io.parse_csv_line()`).\n",
    "* The parsing function should return `(input features, label)`, not a `tf.train.Example`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[1]\n",
    "\n",
    "expected_features = {\n",
    "    \"input_features\": tf.io.FixedLenFeature([n_inputs], dtype=tf.float32),\n",
    "    \"label\": tf.io.FixedLenFeature([1], dtype=tf.float32),\n",
    "}\n",
    "\n",
    "def parse_tfrecord(serialized_example):\n",
    "    example = tf.io.parse_single_example(serialized_example,\n",
    "                                         expected_features)\n",
    "    return example[\"input_features\"], example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfrecords_reader_dataset(filename, batch_size=32,\n",
    "                             shuffle_buffer_size=10000, n_readers=5):\n",
    "    filenames = [name for name in os.listdir() if name.startswith(filename)\n",
    "                                              and name.endswith(\".tfrecords\")]\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filename: tf.data.TFRecordDataset(filename),\n",
    "        cycle_length=n_readers)\n",
    "    dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.apply(\n",
    "        tf.data.experimental.map_and_batch(\n",
    "            parse_tfrecord,\n",
    "            batch_size,\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE))\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tf.Tensor(\n",
      "[[-1.300316    0.5043504  -0.4728457  -0.01471927  0.33010766  0.6962987\n",
      "  -0.81816673  0.6818632 ]\n",
      " [-1.300316    0.5043504  -0.4728457  -0.01471927  0.33010766  0.6962987\n",
      "  -0.81816673  0.6818632 ]\n",
      " [-1.300316    0.5043504  -0.4728457  -0.01471927  0.33010766  0.6962987\n",
      "  -0.81816673  0.6818632 ]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[1.056]\n",
      " [1.056]\n",
      " [1.056]], shape=(3, 1), dtype=float32)\n",
      "\n",
      "X = tf.Tensor(\n",
      "[[-1.300316    0.5043504  -0.4728457  -0.01471927  0.33010766  0.6962987\n",
      "  -0.81816673  0.6818632 ]\n",
      " [-1.300316    0.5043504  -0.4728457  -0.01471927  0.33010766  0.6962987\n",
      "  -0.81816673  0.6818632 ]\n",
      " [ 0.15322134 -1.3151377   0.3427516  -0.12428993  0.55552197 -0.05394736\n",
      "   1.3930548  -0.6625096 ]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[1.056]\n",
      " [1.056]\n",
      " [2.076]], shape=(3, 1), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfrecords_train_set = tfrecords_reader_dataset(\"my_train\", batch_size=3)\n",
    "for X_batch, y_batch in tfrecords_train_set.take(2):\n",
    "    print(\"X =\", X_batch)\n",
    "    print(\"y =\", y_batch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4)\n",
    "Create one dataset for each dataset (`tfrecords_train_set`, `tfrecords_valid_set` and `tfrecords_test_set`), and build, train and evaluate a Keras model using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "tfrecords_train_set = tfrecords_reader_dataset(\"my_train\", batch_size)\n",
    "tfrecords_valid_set = tfrecords_reader_dataset(\"my_valid\", batch_size)\n",
    "tfrecords_test_set = tfrecords_reader_dataset(\"my_test\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 1.7921 - val_loss: 0.9059\n",
      "Epoch 2/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.7073 - val_loss: 0.7734\n",
      "Epoch 3/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.6166 - val_loss: 0.7283\n",
      "Epoch 4/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.5775 - val_loss: 0.6946\n",
      "Epoch 5/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.5511 - val_loss: 0.6669\n",
      "Epoch 6/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.5259 - val_loss: 0.6434\n",
      "Epoch 7/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.5076 - val_loss: 0.6234\n",
      "Epoch 8/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.4923 - val_loss: 0.6059\n",
      "Epoch 9/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.4803 - val_loss: 0.5908\n",
      "Epoch 10/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.4685 - val_loss: 0.5774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f836c13cb70>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[n_inputs]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "\n",
    "model.fit(tfrecords_train_set, steps_per_epoch=len(X_train) // batch_size, epochs=10,\n",
    "          validation_data=tfrecords_valid_set, validation_steps=len(X_valid) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 1ms/step - loss: 0.6554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6553844325475812"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(tfrecords_test_set, steps=len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3183663],\n",
       "       [2.769997 ],\n",
       "       [2.2391286],\n",
       "       ...,\n",
       "       [4.6522207],\n",
       "       [1.9457815],\n",
       "       [2.9506664]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set = test_set.map(lambda X, y: X)\n",
    "model.predict(new_set, steps=len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exercise solution](https://camo.githubusercontent.com/250388fde3fac9135ead9471733ee28e049f7a37/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f302f30362f46696c6f735f736567756e646f5f6c6f676f5f253238666c69707065642532392e6a7067)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 – Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1)\n",
    "Write a `csv_to_tfrecords()` function that will read from a given CSV dataset (e.g., such as `train_set`, passed as an argument), and write the instances to multiple TFRecord files. The number of files should be defined by an `n_shards` argument. If there are, say, 20 shards, then the files should be named `my_train_00000-to-00019.tfrecords` to `my_train_00019-to-00019.tfrecords`, where the `my_train` prefix should be defined by an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(x, y):\n",
    "    input_features = tf.train.FloatList(value=x)\n",
    "    label = tf.train.FloatList(value=y)\n",
    "    features = tf.train.Features(\n",
    "        feature = {\n",
    "            \"input_features\": tf.train.Feature(float_list=input_features),\n",
    "            \"label\": tf.train.Feature(float_list=label),\n",
    "        }\n",
    "    )\n",
    "    example = tf.train.Example(features=features)\n",
    "    return example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_tfrecords(filename, csv_reader_dataset, n_shards, steps_per_shard,\n",
    "                     compression_type=None):\n",
    "    options = tf.io.TFRecordOptions(compression_type=compression_type)\n",
    "    for shard in range(n_shards):\n",
    "        path = \"{}_{:05d}-of-{:05d}.tfrecords\".format(filename, shard, n_shards)\n",
    "        with tf.io.TFRecordWriter(path, options) as writer:\n",
    "            for X_batch, y_batch in csv_reader_dataset.take(steps_per_shard):\n",
    "                for x_instance, y_instance in zip(X_batch, y_batch):\n",
    "                    writer.write(serialize_example(x_instance, y_instance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2)\n",
    "Use this function to write the training set, validation set and test set to multiple TFRecord files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_shards = 20\n",
    "steps_per_shard = len(X_train) // batch_size // n_shards\n",
    "csv_to_tfrecords(\"my_train.tfrecords\", train_set, n_shards, steps_per_shard)\n",
    "\n",
    "n_shards = 1\n",
    "steps_per_shard = len(X_valid) // batch_size // n_shards\n",
    "csv_to_tfrecords(\"my_valid.tfrecords\", valid_set, n_shards, steps_per_shard)\n",
    "\n",
    "n_shards = 1\n",
    "steps_per_shard = len(X_test) // batch_size // n_shards\n",
    "csv_to_tfrecords(\"my_test.tfrecords\", test_set, n_shards, steps_per_shard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3)\n",
    "Write a `tfrecords_reader_dataset()` function, very similar to `csv_reader_dataset()`, that will read from multiple TFRecord files. For convenience, it should take a file prefix (such as `\"my_train\"`) and use `os.listdir()` to look for all the TFRecord files with that prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_features = {\n",
    "    \"input_features\": tf.io.FixedLenFeature([n_inputs], dtype=tf.float32),\n",
    "    \"label\": tf.io.FixedLenFeature([1], dtype=tf.float32),\n",
    "}\n",
    "\n",
    "def parse_tfrecord(serialized_example):\n",
    "    example = tf.io.parse_single_example(serialized_example,\n",
    "                                         expected_features)\n",
    "    return example[\"input_features\"], example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfrecords_reader_dataset(filename, batch_size=32,\n",
    "                             shuffle_buffer_size=10000, n_readers=5):\n",
    "    filenames = [name for name in os.listdir() if name.startswith(filename)\n",
    "                                              and name.endswith(\".tfrecords\")]\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filename: tf.data.TFRecordDataset(filename),\n",
    "        cycle_length=n_readers)\n",
    "    dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.apply(\n",
    "        tf.data.experimental.map_and_batch(\n",
    "            parse_tfrecord,\n",
    "            batch_size,\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE))\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecords_train_set = tfrecords_reader_dataset(\"my_train\", batch_size=3)\n",
    "for X_batch, y_batch in tfrecords_train_set.take(2):\n",
    "    print(\"X =\", X_batch)\n",
    "    print(\"y =\", y_batch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4)\n",
    "Create one dataset for each dataset (`tfrecords_train_set`, `tfrecords_valid_set` and `tfrecords_test_set`), and build, train and evaluate a Keras model using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "tfrecords_train_set = tfrecords_reader_dataset(\"my_train\", batch_size)\n",
    "tfrecords_valid_set = tfrecords_reader_dataset(\"my_valid\", batch_size)\n",
    "tfrecords_test_set = tfrecords_reader_dataset(\"my_test\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[n_inputs]),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(tfrecords_train_set, steps_per_epoch=len(X_train) // batch_size, epochs=10,\n",
    "          validation_data=tfrecords_valid_set, validation_steps=len(X_valid) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(tfrecords_test_set, steps=len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_set = test_set.map(lambda X, y: X)\n",
    "model.predict(new_set, steps=len(X_test) // batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
